{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting up Pandas\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# Setting up Seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "#sns.set_context(\"poster\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('training_data.csv')\n",
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = train.drop('status_group', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = training.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "test = test.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Plot function for Confusion Matrix\n",
    "\n",
    "#plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "labels=['functional','functional needs repair','non functional']\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(shrink=0.7)\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(tick_marks, labels , fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=12)\n",
    "    plt.xlabel('Predicted label', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Because we are having maximum amount of Categorical data let us transform the features, and convert them into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_feature(df, column_name):\n",
    "    unique_values = set(df[column_name].tolist())\n",
    "    transformer_dict = {}\n",
    "    for index, value in enumerate(unique_values):\n",
    "        transformer_dict[value] = index\n",
    "    df[column_name] = df[column_name].apply(lambda y: transformer_dict[y])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "integer_columns = ['days_since_recorded', 'population'] \n",
    "columns_to_transform = [col for col in training.columns if col not in integer_columns]\n",
    "for column in columns_to_transform: \n",
    "    training = transform_feature(training, column)\n",
    "    test = transform_feature(test, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now That we have Cleaned our dataset and Transformed our features, let us train our Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Converting the Training dataframe into a matrix and predictor as y \n",
    "X = training.as_matrix()\n",
    "y = train[\"status_group\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Splitting the Data Set with features into Train set  and Test set to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection \n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, \n",
    "                                                                             y, \n",
    "                                                                             test_size = 0.3, \n",
    "                                                                             random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As a part of EDA let us traing the data using different algorithms and findout which give us the better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "rfc = sklearn.ensemble.RandomForestClassifier(n_estimators=1000, \n",
    "                                              min_samples_split=6,\n",
    "                                              criterion='gini', \n",
    "                                              max_features='auto',\n",
    "                                              oob_score=True,\n",
    "                                              random_state=1,\n",
    "                                              n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Train Accuracy Score : 0.904593554594\n",
      "Random Forest Classifier Test Score : 0.795398428732\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Random Forest Classifier Train Accuracy Score :', rfc.score(X_train, y_train))\n",
    "print('Random Forest Classifier Test Score :', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(criterion='gini',\n",
    "                            max_depth = 10,\n",
    "                            max_features = 'auto',\n",
    "                            random_state = 1,\n",
    "                            splitter = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score : 0.733020683021\n",
      "Test Score : 0.721717171717\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Score :\", dtc.score(X_train, y_train))\n",
    "print(\"Test Score :\", dtc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ETC = ExtraTreesClassifier(n_estimators=1000,min_samples_split=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=1000, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Tree Classifier Training Score : 0.890091390091\n",
      "Extra Tree Classifier Test Score : 0.790572390572\n"
     ]
    }
   ],
   "source": [
    "print('Extra Tree Classifier Training Score :',ETC.score(X_train, y_train))\n",
    "print('Extra Tree Classifier Test Score :',ETC.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scl', StandardScaler()), ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'clf__C':[0.01],\n",
    "                      'clf__class_weight':[None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator = GridSearchCV(estimator=pipe,\n",
    "                                 param_grid=param_grid,\n",
    "                                 n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__C': [0.01], 'clf__class_weight': [None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(training, train.status_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63154882154882153"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(estimator.score(X_test,y_train))\n",
    "\n",
    "estimator.score(training,train.status_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x105e2ad20, file \"/Use...3.6/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/dheerajkrishna/anaconda/lib/python3.6/sit...ges/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/dheer.../python3.6/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x105e2ad20, file \"/Use...3.6/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/dheerajkrishna/anaconda/lib/python3.6/sit...ges/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/dheer.../python3.6/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-06-18T19:41:20.723657', 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'session': '7998EBB4061848128E94D706CF9F07A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'7998EBB4061848128E94D706CF9F07A1']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-06-18T19:41:20.723657', 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'session': '7998EBB4061848128E94D706CF9F07A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'7998EBB4061848128E94D706CF9F07A1'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-06-18T19:41:20.723657', 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'session': '7998EBB4061848128E94D706CF9F07A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\",), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-29-cf999616ceed>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 113369ac8, execution_..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x111e12ed0, file \"<ipython-input-29-cf999616ceed>\", line 4>\n        result = <ExecutionResult object at 113369ac8, execution_..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x111e12ed0, file \"<ipython-input-29-cf999616ceed>\", line 4>, result=<ExecutionResult object at 113369ac8, execution_..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x111e12ed0, file \"<ipython-input-29-cf999616ceed>\", line 4>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ETC': ExtraTreesClassifier(bootstrap=False, class_weig...ate=None,\n           verbose=0, warm_start=False), 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport ma...oster\")\\n\\nget_ipython().magic(\\'matplotlib inline\\')', \"train = pd.read_csv('training_data.csv')\\ntest = pd.read_csv('test_data.csv')\", \"training = train.drop('status_group', axis=1)\", \"training = training.drop('Unnamed: 0', axis=1)\\n\\ntest = test.drop('Unnamed: 0', axis=1)\", \"##Plot function for Confusion Matrix\\n\\n#plt.rcPar...2)\\n    plt.xlabel('Predicted label', fontsize=12)\", 'def transform_feature(df, column_name):\\n    uniq...pply(lambda y: transformer_dict[y])\\n    return df', \"integer_columns = ['days_since_recorded', 'popul...olumn)\\n    test = transform_feature(test, column)\", '## Converting the Training dataframe into a matr...ng.as_matrix()\\ny = train[\"status_group\"].tolist()', 'import sklearn.model_selection \\nX_train, X_test,...                                random_state = 0)', 'import sklearn.ensemble\\n\\nrfc = sklearn.ensemble....                                       n_jobs=-1)', \"rfc.fit(X_train, y_train)\\n\\nprint('Random Forest ...ssifier Test Score :', rfc.score(X_test, y_test))\", 'from sklearn.tree import DecisionTreeClassifier', \"dtc = DecisionTreeClassifier(criterion='gini',\\n ...1,\\n                            splitter = 'best')\", 'dtc.fit(X_train, y_train)', 'print(\"Train Score :\", dtc.score(X_train, y_train))\\nprint(\"Test Score :\", dtc.score(X_test, y_test))', 'from sklearn.ensemble import ExtraTreesClassifie...lassifier(n_estimators=1000,min_samples_split=10)', 'ETC.fit(X_train, y_train)', \"print('Extra Tree Classifier Training Score :',E...assifier Test Score :',ETC.score(X_test, y_test))\", 'from sklearn.svm import LinearSVC\\nfrom sklearn.m...\\nfrom sklearn.preprocessing import StandardScaler', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'Out': {14: DecisionTreeClassifier(class_weight=None, criter...  presort=False, random_state=1, splitter='best'), 17: ExtraTreesClassifier(bootstrap=False, class_weig...ate=None,\n           verbose=0, warm_start=False), 23: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 24: 0.63154882154882153, 25: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 26: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 27: 0.63154882154882153}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ETC': ExtraTreesClassifier(bootstrap=False, class_weig...ate=None,\n           verbose=0, warm_start=False), 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport ma...oster\")\\n\\nget_ipython().magic(\\'matplotlib inline\\')', \"train = pd.read_csv('training_data.csv')\\ntest = pd.read_csv('test_data.csv')\", \"training = train.drop('status_group', axis=1)\", \"training = training.drop('Unnamed: 0', axis=1)\\n\\ntest = test.drop('Unnamed: 0', axis=1)\", \"##Plot function for Confusion Matrix\\n\\n#plt.rcPar...2)\\n    plt.xlabel('Predicted label', fontsize=12)\", 'def transform_feature(df, column_name):\\n    uniq...pply(lambda y: transformer_dict[y])\\n    return df', \"integer_columns = ['days_since_recorded', 'popul...olumn)\\n    test = transform_feature(test, column)\", '## Converting the Training dataframe into a matr...ng.as_matrix()\\ny = train[\"status_group\"].tolist()', 'import sklearn.model_selection \\nX_train, X_test,...                                random_state = 0)', 'import sklearn.ensemble\\n\\nrfc = sklearn.ensemble....                                       n_jobs=-1)', \"rfc.fit(X_train, y_train)\\n\\nprint('Random Forest ...ssifier Test Score :', rfc.score(X_test, y_test))\", 'from sklearn.tree import DecisionTreeClassifier', \"dtc = DecisionTreeClassifier(criterion='gini',\\n ...1,\\n                            splitter = 'best')\", 'dtc.fit(X_train, y_train)', 'print(\"Train Score :\", dtc.score(X_train, y_train))\\nprint(\"Test Score :\", dtc.score(X_test, y_test))', 'from sklearn.ensemble import ExtraTreesClassifie...lassifier(n_estimators=1000,min_samples_split=10)', 'ETC.fit(X_train, y_train)', \"print('Extra Tree Classifier Training Score :',E...assifier Test Score :',ETC.score(X_test, y_test))\", 'from sklearn.svm import LinearSVC\\nfrom sklearn.m...\\nfrom sklearn.preprocessing import StandardScaler', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'Out': {14: DecisionTreeClassifier(class_weight=None, criter...  presort=False, random_state=1, splitter='best'), 17: ExtraTreesClassifier(bootstrap=False, class_weig...ate=None,\n           verbose=0, warm_start=False), 23: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 24: 0.63154882154882153, 25: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 26: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 27: 0.63154882154882153}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/Users/dheerajkrishna/Documents/identifying_faulty_pumps/<ipython-input-29-cf999616ceed> in <module>()\n      1 \n      2 \n      3 param_test1 = {'n_estimators':range(20,81,10)}\n----> 4 estimator = GridSearchCV(estimator = GradientBoostingClassifier(), \n      5                          param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n      6 estimator.fit(X_train, y_train)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e..._score=True,\n       scoring='roc_auc', verbose=0), X=array([[   0,  286,    2, ...,    0,    6,    5]...      [   0, 1003,    2, ...,    0,    4,    4]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...score=True,\n       scoring='roc_auc', verbose=0)>\n        X = array([[   0,  286,    2, ...,    0,    6,    5]...      [   0, 1003,    2, ...,    0,    4,    4]])\n        y = ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...]\n        groups = None\n        self.param_grid = {'n_estimators': range(20, 81, 10)}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e..._score=True,\n       scoring='roc_auc', verbose=0), X=array([[   0,  286,    2, ...,    0,    6,    5]...      [   0, 1003,    2, ...,    0,    4,    4]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 18 19:41:29 2017\nPID: 2373           Python 3.6.0: /Users/dheerajkrishna/anaconda/bin/python\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], make_scorer(roc_auc_score, needs_threshold=True), array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), array([   0,    1,    2, ..., 8507, 8519, 8523]), 0, {'n_estimators': 20}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], make_scorer(roc_auc_score, needs_threshold=True), array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), array([   0,    1,    2, ..., 8507, 8519, 8523]), 0, {'n_estimators': 20})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X=memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), test=array([   0,    1,    2, ..., 8507, 8519, 8523]), verbose=0, parameters={'n_estimators': 20}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    255                              \" numeric value. (Hint: if using 'raise', please\"\n    256                              \" make sure that it has been spelled correctly.)\")\n    257 \n    258     else:\n    259         fit_time = time.time() - start_time\n--> 260         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)\n        X_test = memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]])\n        y_test = ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...]\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n    261         score_time = time.time() - start_time - fit_time\n    262         if return_train_score:\n    263             train_score = _score(estimator, X_train, y_train, scorer)\n    264 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _score(estimator=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X_test=memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]]), y_test=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], scorer=make_scorer(roc_auc_score, needs_threshold=True))\n    283 def _score(estimator, X_test, y_test, scorer):\n    284     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n    285     if y_test is None:\n    286         score = scorer(estimator, X_test)\n    287     else:\n--> 288         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n        estimator = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)\n        X_test = memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]])\n        y_test = ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...]\n    289     if hasattr(score, 'item'):\n    290         try:\n    291             # e.g. unwrap memmapped scalars\n    292             score = score.item()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(roc_auc_score, needs_threshold=True), clf=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X=memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], sample_weight=None)\n    166         \"\"\"\n    167         super(_ThresholdScorer, self).__call__(clf, X, y,\n    168                                                sample_weight=sample_weight)\n    169         y_type = type_of_target(y)\n    170         if y_type not in (\"binary\", \"multilabel-indicator\"):\n--> 171             raise ValueError(\"{0} format is not supported\".format(y_type))\n        y_type = 'multiclass'\n    172 \n    173         if is_regressor(clf):\n    174             y_pred = clf.predict(X)\n    175         else:\n\nValueError: multiclass format is not supported\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 260, in _fit_and_score\n    test_score = _score(estimator, X_test, y_test, scorer)\n  File \"/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 288, in _score\n    score = scorer(estimator, X_test, y_test)\n  File \"/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py\", line 171, in __call__\n    raise ValueError(\"{0} format is not supported\".format(y_type))\nValueError: multiclass format is not supported\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/dheerajkrishna/anaconda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Jun 18 19:41:29 2017\nPID: 2373           Python 3.6.0: /Users/dheerajkrishna/anaconda/bin/python\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], make_scorer(roc_auc_score, needs_threshold=True), array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), array([   0,    1,    2, ..., 8507, 8519, 8523]), 0, {'n_estimators': 20}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], make_scorer(roc_auc_score, needs_threshold=True), array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), array([   0,    1,    2, ..., 8507, 8519, 8523]), 0, {'n_estimators': 20})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X=memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), test=array([   0,    1,    2, ..., 8507, 8519, 8523]), verbose=0, parameters={'n_estimators': 20}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    255                              \" numeric value. (Hint: if using 'raise', please\"\n    256                              \" make sure that it has been spelled correctly.)\")\n    257 \n    258     else:\n    259         fit_time = time.time() - start_time\n--> 260         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)\n        X_test = memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]])\n        y_test = ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...]\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n    261         score_time = time.time() - start_time - fit_time\n    262         if return_train_score:\n    263             train_score = _score(estimator, X_train, y_train, scorer)\n    264 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _score(estimator=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X_test=memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]]), y_test=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], scorer=make_scorer(roc_auc_score, needs_threshold=True))\n    283 def _score(estimator, X_test, y_test, scorer):\n    284     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n    285     if y_test is None:\n    286         score = scorer(estimator, X_test)\n    287     else:\n--> 288         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n        estimator = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)\n        X_test = memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]])\n        y_test = ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...]\n    289     if hasattr(score, 'item'):\n    290         try:\n    291             # e.g. unwrap memmapped scalars\n    292             score = score.item()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(roc_auc_score, needs_threshold=True), clf=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X=memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], sample_weight=None)\n    166         \"\"\"\n    167         super(_ThresholdScorer, self).__call__(clf, X, y,\n    168                                                sample_weight=sample_weight)\n    169         y_type = type_of_target(y)\n    170         if y_type not in (\"binary\", \"multilabel-indicator\"):\n--> 171             raise ValueError(\"{0} format is not supported\".format(y_type))\n        y_type = 'multiclass'\n    172 \n    173         if is_regressor(clf):\n    174             y_pred = clf.predict(X)\n    175         else:\n\nValueError: multiclass format is not supported\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dheerajkrishna/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Jun 18 19:41:29 2017\nPID: 2373           Python 3.6.0: /Users/dheerajkrishna/anaconda/bin/python\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], make_scorer(roc_auc_score, needs_threshold=True), array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), array([   0,    1,    2, ..., 8507, 8519, 8523]), 0, {'n_estimators': 20}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], make_scorer(roc_auc_score, needs_threshold=True), array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), array([   0,    1,    2, ..., 8507, 8519, 8523]), 0, {'n_estimators': 20})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X=memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), test=array([   0,    1,    2, ..., 8507, 8519, 8523]), verbose=0, parameters={'n_estimators': 20}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    255                              \" numeric value. (Hint: if using 'raise', please\"\n    256                              \" make sure that it has been spelled correctly.)\")\n    257 \n    258     else:\n    259         fit_time = time.time() - start_time\n--> 260         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)\n        X_test = memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]])\n        y_test = ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...]\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n    261         score_time = time.time() - start_time - fit_time\n    262         if return_train_score:\n    263             train_score = _score(estimator, X_train, y_train, scorer)\n    264 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _score(estimator=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X_test=memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]]), y_test=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], scorer=make_scorer(roc_auc_score, needs_threshold=True))\n    283 def _score(estimator, X_test, y_test, scorer):\n    284     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n    285     if y_test is None:\n    286         score = scorer(estimator, X_test)\n    287     else:\n--> 288         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n        estimator = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)\n        X_test = memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]])\n        y_test = ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...]\n    289     if hasattr(score, 'item'):\n    290         try:\n    291             # e.g. unwrap memmapped scalars\n    292             score = score.item()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(roc_auc_score, needs_threshold=True), clf=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X=memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], sample_weight=None)\n    166         \"\"\"\n    167         super(_ThresholdScorer, self).__call__(clf, X, y,\n    168                                                sample_weight=sample_weight)\n    169         y_type = type_of_target(y)\n    170         if y_type not in (\"binary\", \"multilabel-indicator\"):\n--> 171             raise ValueError(\"{0} format is not supported\".format(y_type))\n        y_type = 'multiclass'\n    172 \n    173         if is_regressor(clf):\n    174             y_pred = clf.predict(X)\n    175         else:\n\nValueError: multiclass format is not supported\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-cf999616ceed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m estimator = GridSearchCV(estimator = GradientBoostingClassifier(), \n\u001b[1;32m      3\u001b[0m                          param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x105e2ad20, file \"/Use...3.6/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/dheerajkrishna/anaconda/lib/python3.6/sit...ges/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/dheer.../python3.6/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x105e2ad20, file \"/Use...3.6/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/dheerajkrishna/anaconda/lib/python3.6/sit...ges/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/dheer.../python3.6/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-06-18T19:41:20.723657', 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'session': '7998EBB4061848128E94D706CF9F07A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'7998EBB4061848128E94D706CF9F07A1']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-06-18T19:41:20.723657', 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'session': '7998EBB4061848128E94D706CF9F07A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'7998EBB4061848128E94D706CF9F07A1'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-06-18T19:41:20.723657', 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'session': '7998EBB4061848128E94D706CF9F07A1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C8DA3E51050740E39FA68238A739FCE8', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\",), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"param_test1 = {'n_estimators':range(20,81,10)}\\ne...,iid=False, cv=5)\\nestimator.fit(X_train, y_train)\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-29-cf999616ceed>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 113369ac8, execution_..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x111e12ed0, file \"<ipython-input-29-cf999616ceed>\", line 4>\n        result = <ExecutionResult object at 113369ac8, execution_..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x111e12ed0, file \"<ipython-input-29-cf999616ceed>\", line 4>, result=<ExecutionResult object at 113369ac8, execution_..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x111e12ed0, file \"<ipython-input-29-cf999616ceed>\", line 4>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ETC': ExtraTreesClassifier(bootstrap=False, class_weig...ate=None,\n           verbose=0, warm_start=False), 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport ma...oster\")\\n\\nget_ipython().magic(\\'matplotlib inline\\')', \"train = pd.read_csv('training_data.csv')\\ntest = pd.read_csv('test_data.csv')\", \"training = train.drop('status_group', axis=1)\", \"training = training.drop('Unnamed: 0', axis=1)\\n\\ntest = test.drop('Unnamed: 0', axis=1)\", \"##Plot function for Confusion Matrix\\n\\n#plt.rcPar...2)\\n    plt.xlabel('Predicted label', fontsize=12)\", 'def transform_feature(df, column_name):\\n    uniq...pply(lambda y: transformer_dict[y])\\n    return df', \"integer_columns = ['days_since_recorded', 'popul...olumn)\\n    test = transform_feature(test, column)\", '## Converting the Training dataframe into a matr...ng.as_matrix()\\ny = train[\"status_group\"].tolist()', 'import sklearn.model_selection \\nX_train, X_test,...                                random_state = 0)', 'import sklearn.ensemble\\n\\nrfc = sklearn.ensemble....                                       n_jobs=-1)', \"rfc.fit(X_train, y_train)\\n\\nprint('Random Forest ...ssifier Test Score :', rfc.score(X_test, y_test))\", 'from sklearn.tree import DecisionTreeClassifier', \"dtc = DecisionTreeClassifier(criterion='gini',\\n ...1,\\n                            splitter = 'best')\", 'dtc.fit(X_train, y_train)', 'print(\"Train Score :\", dtc.score(X_train, y_train))\\nprint(\"Test Score :\", dtc.score(X_test, y_test))', 'from sklearn.ensemble import ExtraTreesClassifie...lassifier(n_estimators=1000,min_samples_split=10)', 'ETC.fit(X_train, y_train)', \"print('Extra Tree Classifier Training Score :',E...assifier Test Score :',ETC.score(X_test, y_test))\", 'from sklearn.svm import LinearSVC\\nfrom sklearn.m...\\nfrom sklearn.preprocessing import StandardScaler', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'Out': {14: DecisionTreeClassifier(class_weight=None, criter...  presort=False, random_state=1, splitter='best'), 17: ExtraTreesClassifier(bootstrap=False, class_weig...ate=None,\n           verbose=0, warm_start=False), 23: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 24: 0.63154882154882153, 25: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 26: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 27: 0.63154882154882153}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ETC': ExtraTreesClassifier(bootstrap=False, class_weig...ate=None,\n           verbose=0, warm_start=False), 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport ma...oster\")\\n\\nget_ipython().magic(\\'matplotlib inline\\')', \"train = pd.read_csv('training_data.csv')\\ntest = pd.read_csv('test_data.csv')\", \"training = train.drop('status_group', axis=1)\", \"training = training.drop('Unnamed: 0', axis=1)\\n\\ntest = test.drop('Unnamed: 0', axis=1)\", \"##Plot function for Confusion Matrix\\n\\n#plt.rcPar...2)\\n    plt.xlabel('Predicted label', fontsize=12)\", 'def transform_feature(df, column_name):\\n    uniq...pply(lambda y: transformer_dict[y])\\n    return df', \"integer_columns = ['days_since_recorded', 'popul...olumn)\\n    test = transform_feature(test, column)\", '## Converting the Training dataframe into a matr...ng.as_matrix()\\ny = train[\"status_group\"].tolist()', 'import sklearn.model_selection \\nX_train, X_test,...                                random_state = 0)', 'import sklearn.ensemble\\n\\nrfc = sklearn.ensemble....                                       n_jobs=-1)', \"rfc.fit(X_train, y_train)\\n\\nprint('Random Forest ...ssifier Test Score :', rfc.score(X_test, y_test))\", 'from sklearn.tree import DecisionTreeClassifier', \"dtc = DecisionTreeClassifier(criterion='gini',\\n ...1,\\n                            splitter = 'best')\", 'dtc.fit(X_train, y_train)', 'print(\"Train Score :\", dtc.score(X_train, y_train))\\nprint(\"Test Score :\", dtc.score(X_test, y_test))', 'from sklearn.ensemble import ExtraTreesClassifie...lassifier(n_estimators=1000,min_samples_split=10)', 'ETC.fit(X_train, y_train)', \"print('Extra Tree Classifier Training Score :',E...assifier Test Score :',ETC.score(X_test, y_test))\", 'from sklearn.svm import LinearSVC\\nfrom sklearn.m...\\nfrom sklearn.preprocessing import StandardScaler', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'Out': {14: DecisionTreeClassifier(class_weight=None, criter...  presort=False, random_state=1, splitter='best'), 17: ExtraTreesClassifier(bootstrap=False, class_weig...ate=None,\n           verbose=0, warm_start=False), 23: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 24: 0.63154882154882153, 25: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 26: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 27: 0.63154882154882153}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/Users/dheerajkrishna/Documents/identifying_faulty_pumps/<ipython-input-29-cf999616ceed> in <module>()\n      1 \n      2 \n      3 param_test1 = {'n_estimators':range(20,81,10)}\n----> 4 estimator = GridSearchCV(estimator = GradientBoostingClassifier(), \n      5                          param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n      6 estimator.fit(X_train, y_train)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e..._score=True,\n       scoring='roc_auc', verbose=0), X=array([[   0,  286,    2, ...,    0,    6,    5]...      [   0, 1003,    2, ...,    0,    4,    4]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...score=True,\n       scoring='roc_auc', verbose=0)>\n        X = array([[   0,  286,    2, ...,    0,    6,    5]...      [   0, 1003,    2, ...,    0,    4,    4]])\n        y = ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...]\n        groups = None\n        self.param_grid = {'n_estimators': range(20, 81, 10)}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e..._score=True,\n       scoring='roc_auc', verbose=0), X=array([[   0,  286,    2, ...,    0,    6,    5]...      [   0, 1003,    2, ...,    0,    4,    4]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 18 19:41:29 2017\nPID: 2373           Python 3.6.0: /Users/dheerajkrishna/anaconda/bin/python\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], make_scorer(roc_auc_score, needs_threshold=True), array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), array([   0,    1,    2, ..., 8507, 8519, 8523]), 0, {'n_estimators': 20}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], make_scorer(roc_auc_score, needs_threshold=True), array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), array([   0,    1,    2, ..., 8507, 8519, 8523]), 0, {'n_estimators': 20})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X=memmap([[   0,  286,    2, ...,    0,    6,    5...      [   0, 1003,    2, ...,    0,    4,    4]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([ 8189,  8190,  8194, ..., 41577, 41578, 41579]), test=array([   0,    1,    2, ..., 8507, 8519, 8523]), verbose=0, parameters={'n_estimators': 20}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    255                              \" numeric value. (Hint: if using 'raise', please\"\n    256                              \" make sure that it has been spelled correctly.)\")\n    257 \n    258     else:\n    259         fit_time = time.time() - start_time\n--> 260         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)\n        X_test = memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]])\n        y_test = ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...]\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n    261         score_time = time.time() - start_time - fit_time\n    262         if return_train_score:\n    263             train_score = _score(estimator, X_train, y_train, scorer)\n    264 \n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _score(estimator=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X_test=memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]]), y_test=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], scorer=make_scorer(roc_auc_score, needs_threshold=True))\n    283 def _score(estimator, X_test, y_test, scorer):\n    284     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n    285     if y_test is None:\n    286         score = scorer(estimator, X_test)\n    287     else:\n--> 288         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n        estimator = GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False)\n        X_test = memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]])\n        y_test = ['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...]\n    289     if hasattr(score, 'item'):\n    290         try:\n    291             # e.g. unwrap memmapped scalars\n    292             score = score.item()\n\n...........................................................................\n/Users/dheerajkrishna/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(roc_auc_score, needs_threshold=True), clf=GradientBoostingClassifier(criterion='friedman_m...      subsample=1.0, verbose=0, warm_start=False), X=memmap([[  0, 286,   2, ...,   0,   6,   5],\n   ... 1],\n       [  0, 405,   5, ...,   0,   1,   1]]), y=['non functional', 'functional', 'functional', 'functional', 'functional', 'functional needs repair', 'functional', 'functional', 'non functional', 'non functional', 'non functional', 'non functional', 'functional', 'functional', 'functional', 'functional', 'non functional', 'functional', 'non functional', 'non functional', ...], sample_weight=None)\n    166         \"\"\"\n    167         super(_ThresholdScorer, self).__call__(clf, X, y,\n    168                                                sample_weight=sample_weight)\n    169         y_type = type_of_target(y)\n    170         if y_type not in (\"binary\", \"multilabel-indicator\"):\n--> 171             raise ValueError(\"{0} format is not supported\".format(y_type))\n        y_type = 'multiclass'\n    172 \n    173         if is_regressor(clf):\n    174             y_pred = clf.predict(X)\n    175         else:\n\nValueError: multiclass format is not supported\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "param_test1 = {'n_estimators':range(20,81,10)}\n",
    "estimator = GridSearchCV(estimator = GradientBoostingClassifier(), \n",
    "                         param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params = estimator.best_params_\n",
    "print ('Best parameters are:',best_params)\n",
    "                                 \n",
    "val_accuracy = estimator.score(X_test, y_test)\n",
    "print('Gridsearch Accuracy score: ', va1_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters are: {'learning_rate': 0.075, 'max_depth': 7, 'max_features': 1.0, 'min_samples_leaf': 8, 'n_estimators': 200}\n",
    "\n",
    "Gridsearch Accuracy score:  0.791189674523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = ETC.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('SubmissionFormat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Final_merge = pd.concat([test, submission], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>days_since_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>installer</th>\n",
       "      <th>basin</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>321</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>50785</td>\n",
       "      <td>predicted label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>51630</td>\n",
       "      <td>predicted label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17168</td>\n",
       "      <td>predicted label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>45559</td>\n",
       "      <td>predicted label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>251</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>49871</td>\n",
       "      <td>predicted label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  days_since_recorded  funder  installer  basin  population  public_meeting  scheme_management  permit  construction_year  extraction_type_class  payment_type  water_quality  quantity_group  source_type  source_class  waterpoint_type  waterpoint_type_group     id     status_group\n",
       "0           0                  302       2          2      8         321               2                  1       2                  1                      2             4              6               3            2             1                4                      4  50785  predicted label\n",
       "1           0                  302       4          1      0         300               2                  4       2                  4                      6             4              6               4            6             0                5                      5  51630  predicted label\n",
       "2           0                  305       2          2      8         500               2                  4       0                  1                      2             4              6               4            2             1                4                      4  17168  predicted label\n",
       "3           0                  315       2          2      1         250               0                  4       2                  6                      2             1              6               1            5             0                4                      4  45559  predicted label\n",
       "4          65                  251       2          2      1          60               0                  5       2                  4                      6             6              6               2            6             0                5                      5  49871  predicted label"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final_merge['status_group'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Final_merge[['id','status_group']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785      functional\n",
       "1  51630      functional\n",
       "2  17168      functional\n",
       "3  45559  non functional\n",
       "4  49871      functional"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
